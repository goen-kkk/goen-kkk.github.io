<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>DL复习｜机器学习概论 | My New Hugo Site</title><meta name=keywords content="DL"><meta name=description content="机器学习：通过算法使得机器能从大量数据中学习规律从而对新的样本做决策。"><meta name=author content="Me"><link rel=canonical href=https://goen-kkk.github.io/posts/nndl/dl-0/><link crossorigin=anonymous href=/assets/css/stylesheet.min.449b22e16797ccdaf34465d258c12a83c081841b76c2f32e4204d1633d03698c.css integrity="sha256-RJsi4WeXzNrzRGXSWMEqg8CBhBt2wvMuQgTRYz0DaYw=" rel="preload stylesheet" as=style><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta name=twitter:card content="summary"><meta name=twitter:title content="DL复习｜机器学习概论 | My New Hugo Site"><meta name=twitter:description content="机器学习：通过算法使得机器能从大量数据中学习规律从而对新的样本做决策。"><meta property="og:title" content="DL复习｜机器学习概论 | My New Hugo Site"><meta property="og:description" content="机器学习：通过算法使得机器能从大量数据中学习规律从而对新的样本做决策。"><meta property="og:type" content="article"><meta property="og:url" content="https://goen-kkk.github.io/posts/nndl/dl-0/"><meta property="og:image" content="https://goen-kkk.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-13T21:12:25+08:00"><meta property="article:modified_time" content="2023-05-13T21:12:25+08:00"><meta property="og:site_name" content="ExampleSite"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://goen-kkk.github.io/posts/"},{"@type":"ListItem","position":2,"name":"DL复习｜机器学习概论","item":"https://goen-kkk.github.io/posts/nndl/dl-0/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"DL复习｜机器学习概论 | My New Hugo Site","name":"DL复习｜机器学习概论","description":"机器学习：通过算法使得机器能从大量数据中学习规律从而对新的样本做决策。","keywords":["DL"],"wordCount":"119","inLanguage":"en","datePublished":"2023-05-13T21:12:25+08:00","dateModified":"2023-05-13T21:12:25+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://goen-kkk.github.io/posts/nndl/dl-0/"},"publisher":{"@type":"Organization","name":"My New Hugo Site","logo":{"@type":"ImageObject","url":"https://goen-kkk.github.io/favicon.ico"}}}</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="light",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://goen-kkk.github.io/ accesskey=h title="My New Hugo Site (Alt + H)">My New Hugo Site</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://goen-kkk.github.io/archives/ title=Archives>Archives</a></li><li><a href=https://goen-kkk.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://goen-kkk.github.io/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://goen-kkk.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://goen-kkk.github.io/posts/>Posts</a></div><h1 class=post-title>DL复习｜机器学习概论</h1><div class=post-description>机器学习：通过算法使得机器能从大量数据中学习规律从而对新的样本做决策。</div><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>May 13, 2023</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://goen-kkk.github.io/tags/dl/>DL</a></span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>1 min</span></span></div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e6%9c%ac%e8%a6%81%e7%b4%a0 aria-label=机器学习基本要素>机器学习基本要素</a><ul><li><a href=#%e6%a8%a1%e5%9e%8b aria-label=模型>模型</a></li><li><a href=#%e5%ad%a6%e4%b9%a0%e5%87%86%e5%88%99 aria-label=学习准则>学习准则</a></li><li><a href=#%e4%bc%98%e5%8c%96 aria-label=优化>优化</a><ul><li><a href=#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d aria-label=梯度下降>梯度下降</a></li></ul></li></ul></li><li><a href=#%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92 aria-label=线性回归>线性回归</a></li></ul></div></details></div><div class=post-content><h2 id=机器学习基本要素>机器学习基本要素<a hidden class=anchor aria-hidden=true href=#机器学习基本要素>¶</a></h2><p><mark>机器学习的三要素：模型、学习准则、优化。</mark></p><h3 id=模型>模型<a hidden class=anchor aria-hidden=true href=#模型>¶</a></h3><p>线性模型：$f(x,\theta)=\textbf{w}^T\textbf{x}+b$<br>非线性模型：广义的非线性模型可以写为多个非线性基函数𝜙(𝒙) 的线性组合。$f(x,\theta)=\textbf{w}^T\phi(\textbf{x})+b$ 如果 $\phi(\textbf{x})$本身为可学习的基函数，则$f(x,\theta)$就等价于神经网络模型</p><h3 id=学习准则>学习准则<a hidden class=anchor aria-hidden=true href=#学习准则>¶</a></h3><p>模型的好坏可以通过期望风险衡量；
损失函数是非负实数函数，常见的损失函数：</p><ol><li>0-1损失：不连续且导数为 0，难以优化</li><li>平方损失：一般不适用于分类问题。$y$为实数值
$$\mathcal{L}(y, f(\mathbf{x};\theta))=\frac{1}{2}\left(y-f(\mathbf{x};\theta))\right)^2$$</li><li>交叉熵：一般用于分类问题
$\mathbf{y}$为one-hot标签向量
$$
\begin{align}
\mathcal{L}(\mathbf{y}, f(\mathbf{x};\theta))&=-\mathbf{y}\mathrm{log}f(\mathbf{x};\theta) \\
&= - \sum^{C}_{c=1}y_c\mathrm{log}f_c(\mathbf{x};\theta) \\
&= -\mathrm{log}f_y(\mathbf{x};\theta)
\end{align}
$$</li></ol><p>因此，交叉熵损失函数也就是负对数似然函数。</p><p><strong>经验风险最小化</strong>(Empirical Risk Minimization，ERM)原则：找到一组参数使得经验风险最小。<style type=text/css>.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media(prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style><div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379.0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628.0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628.0l-22.627 22.627c-6.248 6.248-6.248 16.379.0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937.0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154.0l239.94 416.028zM288 354c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196.0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627.0 12 5.373 12 12v1e2h12c6.627.0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice info"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#info-notice"/></svg></span>过拟合</p><p>在训练集上错误率很低，但是在未知数据上错误率很高.往往是由于训练数据少和噪声以及模型能力强等原因造成的</p></div></p><p>为了解决过拟合问题， 一般在经验风险最小化的基础上再引入参数的正则化 (Regularization)来<mark>限制模型能力，使其不要过度地最小化经验风险</mark>。这种准则就是<strong>结构风险最小化</strong>(Structure Risk Minimization，SRM)准则
$$
\theta^*=\underset{\theta}{\arg \min } \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(y^{(n)}, f\left(\boldsymbol{x}^{(n)} ; \theta\right)\right)+\lambda \mathscr{l}_p(\theta)
$$
<strong>最大似然估计</strong></p><p><strong>最大后验估计</strong></p><p>所有损害优化的方法都是正则化，包括增加优化约束、干扰优化过程（提前停止、随机梯度下降）
$\mathscr{l}_2$范数正则化项，各个参数的平方和的开方值，用来减少参数空间，避免过拟合;
$\lambda$用来控制正则化的强度。<br>$\mathscr{l}_1$范数正则化项，各个参数的绝对值之和，通常会使得参数有一定稀疏性。</p><p>加入正则化后，参数被限制到了一定的区域，等价于下面带约束条件的优化问题，
$$
\begin{aligned}
& \theta^*=\underset{\theta}{\arg \min } \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(y^{(n)}, f\left(\boldsymbol{x}^{(n)} ; \theta\right)\right), \\
& \text { s.t. } \quad \ell_p(\theta) \leq d
\end{aligned}
$$
$\mathcal{F}$为函数$f(\theta)$的等高线(为简单起见，这里用直线表示)。可以看出，$\mathscr{l}_1$范数的约束通常会使得最优解位于坐标轴上，意味着某一维会变为0，从而使得最终的参数为稀疏性向量。
$\mathscr{l}_2$参数取值空间是圆形，比较平滑，很难与损失函数的曲线相交在顶点上，但是它会使得参数更接近与0。</p><figure><img loading=lazy src=https://s1.ax1x.com/2023/05/13/p962aSx.png alt=不同范数约束条件下的最优化问题示例><figcaption><p>不同范数约束条件下的最优化问题示例</p></figcaption></figure><figure class=align-center><img loading=lazy src=https://image.szdev.com/images/2018/12/03/book-py_ml_2nd-04_05.png#center alt=$\mathscr{l}_2$范数约束条件下的最优化问题示例 width=50%><figcaption><p>$\mathscr{l}_2$范数约束条件下的最优化问题示例</p></figcaption></figure><figure class=align-center><img loading=lazy src=https://image.szdev.com/images/2018/12/03/book-py_ml_2nd-04_06.png#center alt=$\mathscr{l}_1$范数约束条件下的最优化问题示例 width=50%><figcaption><p>$\mathscr{l}_1$范数约束条件下的最优化问题示例</p></figcaption></figure><p>从贝叶斯学习的角度来讲，正则化是引入了参数的先验分布，使其不完全依赖训练数据<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。</p><h3 id=优化>优化<a hidden class=anchor aria-hidden=true href=#优化>¶</a></h3><p>参数是模型的参数
超参数是定义模型结构或优化策略的参数，e.g. learning rate</p><p>针对梯度下降的优化算法，除了加正则化项之外，还可以通过提前停止来防止过拟合。如果在验证集上的错误率不再下降，就停止迭代。</p><h4 id=梯度下降>梯度下降<a hidden class=anchor aria-hidden=true href=#梯度下降>¶</a></h4><p><strong>批量梯度下降法</strong>(Batch Gradient Descent，BGD)在每次迭代时需要计算每个样本上损失函数的梯度并求和。</p><p>在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即<strong>随机梯度下降法</strong>(Stochastic Gradient Descent，SGD)</p><blockquote><p>随机梯度下降实现简单，收敛速度也非常快，因此使用非常广泛。随机梯度下降相当于在批量梯度 下降的梯度上引入了随机噪声，在非凸优化问题中，随机梯度下降更容易逃离局部最优点。</p></blockquote><p><strong>小批量梯度下降法</strong>(Mini-Batch Gradient Descent)是批量梯度下降和随机梯度下 降的折中.每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率</p><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>批量大小的影响</p><p>批量大小不影响随机梯度的期望，但是会影响随机梯度的方差。<br>批量越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定，因此可以设置较大的学习率。<br>而批量较小时，需要设置较小的学习率，否则模型会不收敛。</p></div><figure><img loading=lazy src=https://i.328888.xyz/2023/05/18/VVXCjJ.png alt=小批量梯度下降中，每次选取样本数量对损失下降的影响><figcaption><p>小批量梯度下降中，每次选取样本数量对损失下降的影响</p></figcaption></figure><ul><li>从(a)可以看出，每次迭代选取的批量样本数越多，下降效果越明显，并且曲线越平滑。当每次选取一个样本时（相当于随机梯度下降），损失整体是下降趋势，但局部看会来回震荡。</li><li>从(b)可以看出，如果按整个数据集迭代的来看损失变化情况，则小批量样本数越小，下降效果越明显。</li></ul><h2 id=线性回归>线性回归<a hidden class=anchor aria-hidden=true href=#线性回归>¶</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>TODO&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><nav class=paginav><a class=prev href=https://goen-kkk.github.io/posts/pieces/magnolia/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>读一首诗再睡觉｜MAGNOLIA</span></a>
<a class=next href=https://goen-kkk.github.io/posts/interv/transformer/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>Interview｜Transformer</span></a></nav></footer><div class=comments-separator></div></article></main><footer class=footer><span>&copy; 2023 <a href=https://goen-kkk.github.io/>My New Hugo Site</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a></span>
<span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script>
<script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>