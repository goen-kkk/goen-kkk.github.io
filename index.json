[{"content":"1 安装Hugo [Mac] 官网教程\n安装brew 1 ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; 运行brew安装hugo 1 brew install hugo 2 生成站点 1 2 hugo new site /path/to/site -f yml \\ \u0026amp;\u0026amp; cd /path/to/site 3 安装主题 在你的站点文件夹运行\n1 git clone https://github.com/reorx/hugo-PaperModX themes/PaperModX --depth=1 Sample config.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 baseURL: \u0026#34;https://examplesite.com/\u0026#34; languageCode: en-us title: My New Hugo Site theme: PaperModX enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false pygmentsUseClasses: true googleAnalytics: UA-123-45 enableEmoji: true minify: disableXML: true minifyOutput: true params: env: production # to enable google analytics, opengraph, twitter-cards and schema. title: ExampleSite description: \u0026#34;ExampleSite description\u0026#34; keywords: [Blog, Portfolio, PaperModX] author: Me # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors images: [\u0026#34;\u0026lt;link or path of image for opengraph, twitter-cards\u0026gt;\u0026#34;] DateFormat: \u0026#34;January 2, 2006\u0026#34; defaultTheme: auto # dark, light disableThemeToggle: false ShowReadingTime: true ShowShareButtons: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true # 显示代码复制按钮 disableSpecial1stPost: false disableScrollToTop: false comments: false hidemeta: false hideSummary: false showtoc: false tocopen: false math: true # MathJex设置 homeInfoParams: Title: Hi there wave Content: Can be Info, links, about.. socialIcons: # optional - name: \u0026#34;\u0026lt;platform\u0026gt;\u0026#34; url: \u0026#34;\u0026lt;link\u0026gt;\u0026#34; - name: \u0026#34;\u0026lt;platform 2\u0026gt;\u0026#34; url: \u0026#34;\u0026lt;link2\u0026gt;\u0026#34; assets: # disableFingerprinting: true favicon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon16x16: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon32x32: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; apple_touch_icon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; safari_pinned_tab: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; label: text: \u0026#34;Home\u0026#34; icon: /apple-touch-icon.png iconHeight: 35 # profile-mode profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#34;This is subtitle\u0026#34; imageUrl: \u0026#34;\u0026lt;img location\u0026gt;\u0026#34; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: Posts url: posts - name: Tags url: tags # home-info mode homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: Welcome to my blog socialIcons: - name: twitter url: \u0026#34;https://twitter.com/\u0026#34; - name: stackoverflow url: \u0026#34;https://stackoverflow.com\u0026#34; - name: github url: \u0026#34;https://github.com/\u0026#34; analytics: google: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; bing: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; yandex: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page # responsiveImages: false # To reduce generation time and size of the site, you can disable this feature # linkFullImages: true # To enable hyperlinks to the full image size on post pages editPost: URL: \u0026#34;https://github.com/\u0026lt;path_to_repo\u0026gt;/content\u0026#34; Text: \u0026#34;Suggest Changes\u0026#34; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] menu: main: - identifier: Archives name: Archives url: /archives/ weight: 10 # - identifier: categories # name: categories # url: /categories/ # weight: 10 - identifier: Tags name: Tags url: /tags/ weight: 20 # - identifier: example # name: example.org # url: https://example.org # weight: 30 - identifier: Search name: Search url: /search weight: 30 outputs: home: - HTML - RSS - JSON # is necessary # Read: https://github.com/reorx/hugo-PaperModX/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: # 代码高亮 # anchorLineNos: true codeFences: true guessSyntax: true lineNos: true style: monokai goldmark: renderer: unsafe: true # 关闭安全模式 新建文章 1 hugo new posts/yourarticlename.md 本地调试 执行命令后，在浏览器打开http://localhost:1313可预览网站\n1 hugo server -D -D可看到草稿文章\n部署Github 1 hugo ##生成静态页面文件 在命令执行后，出现一个public文件夹，里面就是网站的静态页面文件 进入public文件夹，使用git上传文件\n1 2 3 4 5 6 cd public git init ##初始化仓库 git remote add origin https://github.com/caecarxu/caecarxu.github.io.git ##链接远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master 在此之后更新文章，使用hugo生成新的静态页面，并使用git push进行同步\n1 2 3 4 5 cd public git add . git status git commit -m \u0026#34;add blog post\u0026#34; git push 5 主题设置 MathJex 创建partials/math.html文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;!-- Mathjex --\u0026gt; \u0026lt;script\u0026gt; MathJax = { tex: { inlineMath: [[\u0026#39;$\u0026#39;, \u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;, \u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\\\[\u0026#39;, \u0026#39;\\\\]\u0026#39;]], processEscapes: true, processEnvironments: true }, options: { skipHtmlTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;] } }; window.addEventListener(\u0026#39;load\u0026#39;, (event) =\u0026gt; { document.querySelectorAll(\u0026#34;mjx-container\u0026#34;).forEach(function(x){ x.parentElement.classList += \u0026#39;has-jax\u0026#39;}) }); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://polyfill.io/v3/polyfill.min.js?features=es6\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; id=\u0026#34;MathJax-script\u0026#34; async src=\u0026#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 在blank.css中添加\n1 2 3 4 5 6 code.has-jax { -webkit-font-smoothing: antialiased; background: inherit !important; border: none !important; font-size: 100%; } 全局开启公式渲染，在partials/extend_head.html中加入\n1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} 在config.yml中加入\n1 2 params: math: true 图片caption居中 在blank.css中添加\n1 2 3 figcaption { text-align: center; } 进一步更改图片caption样式可以在main.css中更改.post-warp .post-content .image-caption:not(:empty) 元素的值，例如\n1 2 3 4 5 6 7 8 9 10 11 .post-warp .post-content .image-caption:not(:empty) { min-width: 20%; max-width: max-content; /* display: inline-block; */ padding: 3px; margin: 8px auto; border-bottom: 1px solid #d9d9d9; font-size: 14px; color: #969696; line-height: 1.7; } 显示代码copy按钮 1 ShowCodeCopyButtons: true 可以在main.css中修改codecopybutton样式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 .copy-code { display: none; position: absolute; top: 4px; right: 4px; color: rgba(255, 255, 255, 0.8); background: rgba(78, 78, 78, 0.8); border-radius: var(--radius); padding: 0 5px; font-size: 14px; user-select: none; } div.highlight:hover .copy-code, pre:hover .copy-code { display: block; } 代码块滚动 通过css控制，给代码块设置个最大高度。在blank.css中添加：\n1 2 3 pre { max-height: 500px; } shortcode 标签，源文件来自@martignoni 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 {{/* Available notice types: warning, info, note, tip */}} {{- $noticeType := .Get 0 | default \u0026#34;note\u0026#34; -}} {{- $title := .Get 1 | default $noticeType -}} {{/* Workaround markdownify inconsistency for single/multiple paragraphs */}} {{- $raw := (markdownify .Inner | chomp) -}} {{- $block := findRE \u0026#34;(?is)^\u0026lt;(?:address|article|aside|blockquote|canvas|dd|div|dl|dt|fieldset|figcaption|figure|footer|form|h(?:1|2|3|4|5|6)|header|hgroup|hr|li|main|nav|noscript|ol|output|p|pre|section|table|tfoot|ul|video)\\\\b\u0026#34; $raw 1 -}} {{/* Count how many times we\u0026#39;ve called this shortcode and load the css if it\u0026#39;s the first time */}} {{- if not ($.Page.Scratch.Get \u0026#34;noticecount\u0026#34;) -}} \u0026lt;!-- \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt;.notice{--root-color:#444;--root-background:#e8e3f6b3;--title-color:#444;--title-background:#e8e3f6;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e8e3f6b3;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}\u0026lt;/style\u0026gt; --\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt;.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}\u0026lt;/style\u0026gt; \u0026lt;div\u0026gt;\u0026lt;svg width=\u0026#34;0\u0026#34; height=\u0026#34;0\u0026#34; display=\u0026#34;none\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u0026gt;\u0026lt;symbol id=\u0026#34;tip-notice\u0026#34; viewBox=\u0026#34;0 0 512 512\u0026#34; preserveAspectRatio=\u0026#34;xMidYMid meet\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z\u0026#34;/\u0026gt;\u0026lt;/symbol\u0026gt;\u0026lt;symbol id=\u0026#34;note-notice\u0026#34; viewBox=\u0026#34;0 0 512 512\u0026#34; preserveAspectRatio=\u0026#34;xMidYMid meet\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z\u0026#34;/\u0026gt;\u0026lt;/symbol\u0026gt;\u0026lt;symbol id=\u0026#34;warning-notice\u0026#34; viewBox=\u0026#34;0 0 576 512\u0026#34; preserveAspectRatio=\u0026#34;xMidYMid meet\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z\u0026#34;/\u0026gt;\u0026lt;/symbol\u0026gt;\u0026lt;symbol id=\u0026#34;info-notice\u0026#34; viewBox=\u0026#34;0 0 512 512\u0026#34; preserveAspectRatio=\u0026#34;xMidYMid meet\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\u0026#34;/\u0026gt;\u0026lt;/symbol\u0026gt;\u0026lt;/svg\u0026gt;\u0026lt;/div\u0026gt; {{- end -}} {{- $.Page.Scratch.Add \u0026#34;noticecount\u0026#34; 1 -}} \u0026lt;div class=\u0026#34;notice {{ $noticeType }}\u0026#34; {{ if len .Params | eq 3 }} id=\u0026#34;{{ .Get 2 }}\u0026#34; {{ end }}\u0026gt; \u0026lt;p class=\u0026#34;first notice-title\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;icon-notice baseline\u0026#34;\u0026gt;\u0026lt;svg\u0026gt;\u0026lt;use href=\u0026#34;#{{- $noticeType -}}-notice\u0026#34;\u0026gt;\u0026lt;/use\u0026gt;\u0026lt;/svg\u0026gt;\u0026lt;/span\u0026gt;{{ $title }}\u0026lt;/p\u0026gt; {{- if or $block (not $raw) }}{{ $raw }}{{ else }}\u0026lt;p\u0026gt;{{ $raw }}\u0026lt;/p\u0026gt;{{ end -}} \u0026lt;/div\u0026gt; 效果如下： title\nThis is a tip.\ntitle\nThis is a notice.\ntitle\nThis is a warning.\ntitle\nThis is a info.\n参考链接\nhttps://shishuochen.github.io/2022/cpvuqozuc/ 3rd\u0026rsquo;s Blog irithys shishuochen sulvblog limp ","permalink":"https://goen-kkk.github.io/posts/post/","summary":"1 安装Hugo [Mac] 官网教程\n安装brew 1 ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; 运行brew安装hugo 1 brew install hugo 2 生成站点 1 2 hugo new site /path/to/site -f yml \\ \u0026amp;\u0026amp; cd /path/to/site 3 安装主题 在你的站点文件夹运行\n1 git clone https://github.com/reorx/hugo-PaperModX themes/PaperModX --depth=1 Sample config.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 baseURL: \u0026#34;https://examplesite.","title":"HUGO博客搭建｜PaperModeX主题"},{"content":"研究背景 研究问题 随着云计算的出现，许多传统的软件系统被迁移到云计算平台上作为在线服务。云服务质量于用户体验而言至关重要。由于在线服务需要服务全球数以百万计的客户，短时间的性能下降可能导致经济损失和用户不满。因此，主动甚至自适应的系统排故成为在线服务提供商的核心能力。\n云服务通过各种指标来监控逻辑资源(例如,一个虚拟机)和物理资源(例如,一个计算服务器)的各个方面。我们观察到当相似类型的性能异常发生时，它们往往会在指标时间序列上触发类似的反应/症状，我们称之为指标模式（metric pattern）。 比如服务性能瓶颈通常表现为吞吐量下降及CPU利用率上升，如图1所示。每个指标时间序列记录了一周左右的监测数据，其异常表现由红色表示。 Figure 1: 性能异常模式案例\n指标异常检测旨在找到指标序列（一种时序数据）中预期之外的或者罕见的模式，从而及时发现服务中的性能问题。\n传统解决方案的问题 在对指标值进行异常检测时，现有方法往往缺乏可解释性，这对于工程师和分析人员采取补救措施至关重要。而且，它们无法有效地以在线方式适应不断变化的服务。\n算法结果可解释：现有工作大多是为指标序列的每个节点计算一个异常概率，并通过设置阈值的方式判断异常是否发生。然而这样的结果对运维人员的作用十分有限。由于算法无法进一步提供异常是由哪些故障/问题导致的，运维人员难以相信算法结果，需要手工排查大量指标进行问题定位。因此，可解释性对于故障分析与服务恢复具有重要作用。 异常模式在线更新：实际场景中，在线服务频繁变更（比如系统架构发生变化，新功能上线），异常模式也可能随之改变。现有工作大多通过历史离线数据训练学习异常检测模式，难以适应频繁变化的异常模式。因此现有工作部署在实际系统时，随着时间的推移将产生较多误报。 本文方案 针对以上局限性，作者提出了一种基于模式草图的在线服务系统性能异常检测方法ADSketch，该方法具有可解释性和自适应性。 其主要思想是从度量时间序列中识别出能够表示服务性能问题类别的判别性子序列。 ADSketch通过识别代表特定类型性能问题的一组异常度量模式来实现可解释性。如果类似的模式再次出现，潜在的问题就可以立即被认识到。此外，还设计了自适应学习算法，以适应由服务更新或用户行为变化引起的前所未有的模式。\n整体框架 共分为两个阶段：离线异常检测（offline phase）及在线异常检测（online phase）。在离线阶段，输入为一对指标序列，一个是不包含异常的指标序列（anomaly-free metric），用来作为正常指标的参考基准；另一个输入为需要进行异常检测的指标序列（metric for anomaly detection）。这个阶段将学习到两种指标模式，即正常模式（normal patterns）和异常模式（abnormal patterns）。特别地，指标模式为一组相似的子序列通过求平均获得。运维人员在日常故障处理过程中把服务性能问题与学习到的异常模式进行关联，以实现知识的积累。在线阶段则利用离线阶段捕获的模式进行快速的异常检测，同时对已习得的模式进行更新（adaptive pattern learning）。 Figure 2: ADSketch整体框架\nTable 1: 变量汇总\n离线异常检测 离线阶段的一个重要目标是发现指标模式。主要思想为，如果一个子序列显著偏离正常时期的子序列，那么它是一种异常模式。偏移程度用两个子序列的距离来度量，如果距离越大，说明越可能异常。对于一个长度为$l$的指标序列，假设子序列的长度为$m$，那该指标序列有$l-m+1$条子序列。通过计算这些子序列两两之间的距离，我们可以得到每一条子序列距离其他子序列最小的值，我们称为the smallest pair-wise distance（简称SPW距离）。SPW越大，则表明该子序列越偏离整体指标序列（与其他所有子序列的相似度较低），因此也越可能是异常。从图3可以看出，异常区间的SPW距离显著高于正常区间的，作者采用欧氏距离作为距离度量函数，并且采用STAMP算法进行快速的SPW距离计算。 Figure 3: 指标序列不同子序列的SPW距离\n具体算法 $\\mathcal{T}_n$为输入的正常指标序列，$\\mathcal{T}_a$为需要进行异常检测的序列，$m$为子序列长度，$p$为分位数阈值（用来划定异常子序列，为了降低漏报率，该参数设置的比较宽松），$I$和$S$为子序列的索引以及子序列的SPW距离。算法流程如下： Figure 4: 指标模式发现算法\n1：在$\\mathcal{T}_n$内部计算SPW距离（self-join），即进行距离计算的子序列均取自$\\mathcal{T}_n$，见图5第1部分。\n2：对于$\\mathcal{T}_a$​的子序列，从$\\mathcal{T}_n$找与其最相似的子序列（cross-join），即进行距离计算的子序列分别来自$\\mathcal{T}_a$​和$\\mathcal{T}_n$。由于$\\mathcal{T}_n$​为正常序列，因此SPW距离较大的$\\mathcal{T}_a$​的子序列有可能为异常，由分位数阈值$p$划定正常与异常子序列，见图5第1部分。\n3-4：构建连通图$G$，图中的节点为来自$\\mathcal{T}_n$​和$\\mathcal{T}_a$的所有子序列，两个节点有连线则表明它们在self-join和cross-join中取得SPW距离，即最相似。接着按照$p$划定的距离阈值将大于$p$的边剪断，这将产生孤立节点，孤立节点可以认为是候选的异常子序列$N_i$​，见图5第2部分。这里连接子图里的序列不能代表相似的指标模式，主要有两个原因：一是图的构造条件比较严格，只考虑了最近邻连接，不同子图之间也可能比较相似；二是由于百分位阈值$p$设置得比较宽松，可能会产生误报。\n5-6：对每个子图里的子序列计算均值$\\mu_G$​，并采用Affinity Propagation算法对均值向量做进一步聚类$C$。由此将所有相似的子序列尽可能地聚合在一起。\n7-15：对进一步聚类得到的子序列簇$C$再次计算均值$\\mu_C$​​，得到的均值向量作为指标模式。如果这个簇中所有的子序列均来自前面的候选异常子序列，则判定该指标模式为异常模式$P_a$​，否则为正常模式$P_n$​，见图5第3部分。\nFigure 5: 指标模式发现算法（图示）\n指标模式的可解释性 对于每个度量模式，域工程师将标注触发它的性能问题的类型。特别地，一个模式可以同时具有多个标签。具有重叠的度量模式将共享同一组性能问题标签。\n在线异常检测 利用离线学习到的异常模式，我们能快速进行异常检测。输入一个长度为$m$的子序列$t$，计算$t$到上一步中学习到的所有模式的距离，我们搜索其最相似的度量模式，并检查它来自哪个模式池。\n具体算法 1-2：给定一个新的长度为$m$的度量子序列$t$，搜索其最相似的度量模式。\n3-7：如果$t$与异常模式更相似，则预测为异常；否则为正常。\nFigure 6: 在线异常检测算法\n指标模式自适应学习 由于云服务经常需要更新或新功能上线，指标模式也随之发生变化。作者提出在线更新离线过程中学习到的指标模式，如图7所示。算法的核心思想为，如果一个新的子序列$t$距离现有的模式（由相似子序列组成的簇计算均值得到）较近，则$t$将被吸收进现有的簇中并更新该簇，否则$t$将作为新的模式自组成一个新的簇。记$S_C​$为聚类簇的大小（即该簇包含的子序列数量），$R_C​$为聚类簇的半径（簇中心到所包含的子序列的最大距离），$\\mu_C$为聚类簇中心（即簇所包含子序列的均值）。\n具体算法 1-2：首先寻找$t$最接近的模式。\n3：均值向量$\\mu_C$更新方程。\n4-6：半径$R_C[idx]$的更新值。\n7：考虑到正常团簇和异常团簇之间的高度不平衡性，我们为它们保持两个最大半径，分别记为$d_n$和$d_a$\n8：一旦一个簇改变了它的半径，我们重置了它的类的最大半径。\n9-16：集群接受一个新成员，需要更新其均值向量$\\mu_C[idx]$(即度量模式，通过第3行的公式更新)、大小$S_C[idx]$（加一）和半径$R_C[idx]$。\n11：对新形成的异常团簇的大小设置阈值来减轻假阳性。\n12-13：当集群的规模超过阈值时，集群的角色将从异常切换到正常。\n18-21：另一方面，如果簇拒绝$t$，我们通过适当地设置它的性质，形成一个新的只包含$t$的反常簇。\nFigure 7: 指标模式在线更新算法\n半径$R_C[idx]$的更新有点问题。由于原始子序列不可得，我们无法直接计算新的半径。为了解决这个问题，我们使用最坏情况距离进行近似。如图5所示，当$t$位于产生半径(记为$t_r$)的杆件处切空间的(向内指)法线时，新半径达到最大值。\nFigure 8: 簇半径的更新\n实验评估 通过从华为云中具有代表性的在线服务系统收集的公共数据和工业数据对所提方法进行评估。实验结果表明，ADSketch算法的性能明显优于现有的方法，证明了在线算法在新模式发现中的有效性。\n复现结果 时间\u0026amp;资源\n个人总结 ","permalink":"https://goen-kkk.github.io/posts/papers/adsketch/","summary":"研究背景 研究问题 随着云计算的出现，许多传统的软件系统被迁移到云计算平台上作为在线服务。云服务质量于用户体验而言至关重要。由于在线服务需要服务全球数以百万计的客户，短时间的性能下降可能导致经济损失和用户不满。因此，主动甚至自适应的系统排故成为在线服务提供商的核心能力。\n云服务通过各种指标来监控逻辑资源(例如,一个虚拟机)和物理资源(例如,一个计算服务器)的各个方面。我们观察到当相似类型的性能异常发生时，它们往往会在指标时间序列上触发类似的反应/症状，我们称之为指标模式（metric pattern）。 比如服务性能瓶颈通常表现为吞吐量下降及CPU利用率上升，如图1所示。每个指标时间序列记录了一周左右的监测数据，其异常表现由红色表示。 Figure 1: 性能异常模式案例\n指标异常检测旨在找到指标序列（一种时序数据）中预期之外的或者罕见的模式，从而及时发现服务中的性能问题。\n传统解决方案的问题 在对指标值进行异常检测时，现有方法往往缺乏可解释性，这对于工程师和分析人员采取补救措施至关重要。而且，它们无法有效地以在线方式适应不断变化的服务。\n算法结果可解释：现有工作大多是为指标序列的每个节点计算一个异常概率，并通过设置阈值的方式判断异常是否发生。然而这样的结果对运维人员的作用十分有限。由于算法无法进一步提供异常是由哪些故障/问题导致的，运维人员难以相信算法结果，需要手工排查大量指标进行问题定位。因此，可解释性对于故障分析与服务恢复具有重要作用。 异常模式在线更新：实际场景中，在线服务频繁变更（比如系统架构发生变化，新功能上线），异常模式也可能随之改变。现有工作大多通过历史离线数据训练学习异常检测模式，难以适应频繁变化的异常模式。因此现有工作部署在实际系统时，随着时间的推移将产生较多误报。 本文方案 针对以上局限性，作者提出了一种基于模式草图的在线服务系统性能异常检测方法ADSketch，该方法具有可解释性和自适应性。 其主要思想是从度量时间序列中识别出能够表示服务性能问题类别的判别性子序列。 ADSketch通过识别代表特定类型性能问题的一组异常度量模式来实现可解释性。如果类似的模式再次出现，潜在的问题就可以立即被认识到。此外，还设计了自适应学习算法，以适应由服务更新或用户行为变化引起的前所未有的模式。\n整体框架 共分为两个阶段：离线异常检测（offline phase）及在线异常检测（online phase）。在离线阶段，输入为一对指标序列，一个是不包含异常的指标序列（anomaly-free metric），用来作为正常指标的参考基准；另一个输入为需要进行异常检测的指标序列（metric for anomaly detection）。这个阶段将学习到两种指标模式，即正常模式（normal patterns）和异常模式（abnormal patterns）。特别地，指标模式为一组相似的子序列通过求平均获得。运维人员在日常故障处理过程中把服务性能问题与学习到的异常模式进行关联，以实现知识的积累。在线阶段则利用离线阶段捕获的模式进行快速的异常检测，同时对已习得的模式进行更新（adaptive pattern learning）。 Figure 2: ADSketch整体框架\nTable 1: 变量汇总\n离线异常检测 离线阶段的一个重要目标是发现指标模式。主要思想为，如果一个子序列显著偏离正常时期的子序列，那么它是一种异常模式。偏移程度用两个子序列的距离来度量，如果距离越大，说明越可能异常。对于一个长度为$l$的指标序列，假设子序列的长度为$m$，那该指标序列有$l-m+1$条子序列。通过计算这些子序列两两之间的距离，我们可以得到每一条子序列距离其他子序列最小的值，我们称为the smallest pair-wise distance（简称SPW距离）。SPW越大，则表明该子序列越偏离整体指标序列（与其他所有子序列的相似度较低），因此也越可能是异常。从图3可以看出，异常区间的SPW距离显著高于正常区间的，作者采用欧氏距离作为距离度量函数，并且采用STAMP算法进行快速的SPW距离计算。 Figure 3: 指标序列不同子序列的SPW距离\n具体算法 $\\mathcal{T}_n$为输入的正常指标序列，$\\mathcal{T}_a$为需要进行异常检测的序列，$m$为子序列长度，$p$为分位数阈值（用来划定异常子序列，为了降低漏报率，该参数设置的比较宽松），$I$和$S$为子序列的索引以及子序列的SPW距离。算法流程如下： Figure 4: 指标模式发现算法\n1：在$\\mathcal{T}_n$内部计算SPW距离（self-join），即进行距离计算的子序列均取自$\\mathcal{T}_n$，见图5第1部分。\n2：对于$\\mathcal{T}_a$​的子序列，从$\\mathcal{T}_n$找与其最相似的子序列（cross-join），即进行距离计算的子序列分别来自$\\mathcal{T}_a$​和$\\mathcal{T}_n$。由于$\\mathcal{T}_n$​为正常序列，因此SPW距离较大的$\\mathcal{T}_a$​的子序列有可能为异常，由分位数阈值$p$划定正常与异常子序列，见图5第1部分。\n3-4：构建连通图$G$，图中的节点为来自$\\mathcal{T}_n$​和$\\mathcal{T}_a$的所有子序列，两个节点有连线则表明它们在self-join和cross-join中取得SPW距离，即最相似。接着按照$p$划定的距离阈值将大于$p$的边剪断，这将产生孤立节点，孤立节点可以认为是候选的异常子序列$N_i$​，见图5第2部分。这里连接子图里的序列不能代表相似的指标模式，主要有两个原因：一是图的构造条件比较严格，只考虑了最近邻连接，不同子图之间也可能比较相似；二是由于百分位阈值$p$设置得比较宽松，可能会产生误报。\n5-6：对每个子图里的子序列计算均值$\\mu_G$​，并采用Affinity Propagation算法对均值向量做进一步聚类$C$。由此将所有相似的子序列尽可能地聚合在一起。\n7-15：对进一步聚类得到的子序列簇$C$再次计算均值$\\mu_C$​​，得到的均值向量作为指标模式。如果这个簇中所有的子序列均来自前面的候选异常子序列，则判定该指标模式为异常模式$P_a$​，否则为正常模式$P_n$​，见图5第3部分。\nFigure 5: 指标模式发现算法（图示）\n指标模式的可解释性 对于每个度量模式，域工程师将标注触发它的性能问题的类型。特别地，一个模式可以同时具有多个标签。具有重叠的度量模式将共享同一组性能问题标签。\n在线异常检测 利用离线学习到的异常模式，我们能快速进行异常检测。输入一个长度为$m$的子序列$t$，计算$t$到上一步中学习到的所有模式的距离，我们搜索其最相似的度量模式，并检查它来自哪个模式池。\n具体算法 1-2：给定一个新的长度为$m$的度量子序列$t$，搜索其最相似的度量模式。\n3-7：如果$t$与异常模式更相似，则预测为异常；否则为正常。\nFigure 6: 在线异常检测算法\n指标模式自适应学习 由于云服务经常需要更新或新功能上线，指标模式也随之发生变化。作者提出在线更新离线过程中学习到的指标模式，如图7所示。算法的核心思想为，如果一个新的子序列$t$距离现有的模式（由相似子序列组成的簇计算均值得到）较近，则$t$将被吸收进现有的簇中并更新该簇，否则$t$将作为新的模式自组成一个新的簇。记$S_C​$为聚类簇的大小（即该簇包含的子序列数量），$R_C​$为聚类簇的半径（簇中心到所包含的子序列的最大距离），$\\mu_C$为聚类簇中心（即簇所包含子序列的均值）。","title":"Paper｜ADSketch"},{"content":"0 Abstract Recently, \u0026hellip; has been gaining significant attention from society.\nmany individuals are seeking to uncover the background and secrets behind its impressive performance.\n1 Introduction In addition to the benefits brought by the increase in data volume and computational power, researchers are also exploring ways to integrate new technologies with GAI algorithms.\nHowever, it wasn’t until the advent of deep learning that generative models saw significant improvements in performance.\nTransformer has later been applied in CV and then become the dominant backbone for many generative models in various domains In the field of \u0026hellip;\nnon-trivial 很重要 they are unable to effectively accommodate the ever-changing services in an online fashion.适应，adapt to\n","permalink":"https://goen-kkk.github.io/posts/paperw/","summary":"0 Abstract Recently, \u0026hellip; has been gaining significant attention from society.\nmany individuals are seeking to uncover the background and secrets behind its impressive performance.\n1 Introduction In addition to the benefits brought by the increase in data volume and computational power, researchers are also exploring ways to integrate new technologies with GAI algorithms.\nHowever, it wasn’t until the advent of deep learning that generative models saw significant improvements in performance.","title":"Collection｜Paperwriting"},{"content":" 玉兰花 今年的春夏两季决心要\n加快速度，把自己打包成一个\n为时三天的季节\n从冬天里蒸腾而出。\n前面院子里那一树不情愿的\n玉兰花苞失去了控制\n忽然间怒放开来。\n两天后，绸缎般淡粉色的花瓣\n围着树干堆积着\n就像脱下来的衬裙。\n还记得从前的春天有多长吗？\n还记得从第一次牵住手指。\n到第一次真正的吻曾经需要多久吗？而这之后。\n还记得另一次漫长的等待，无尽的摩挲。\n就为了解开一粒纽扣吗？\n作者 / [美国]丽泽·穆勒1\nMAGNOLIA This year spring and summer decided\nto make it quick, roll themselves into one\nseason of three days\nand steam right out of winter.\nIn the front yard the reluctant\nmagnolia buds lost control\nand suddenly stood wide open.\nTwo days later their pale pink silks\nheaped up around the trunk\nlike cast-off petticoats.\nRemember how long spring used to take?\nAnd how long from the first locking of fingers\nto the first real kiss? And after that\nthe other eternity, endless motion\ntoward the undoing of a button?\nby Lisel Mueller\n翻译：唐小兵；《我深爱我们一起相处的这些夜晚》，上海文艺出版社\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://goen-kkk.github.io/posts/pieces/magnolia/","summary":"玉兰花 今年的春夏两季决心要\n加快速度，把自己打包成一个\n为时三天的季节\n从冬天里蒸腾而出。\n前面院子里那一树不情愿的\n玉兰花苞失去了控制\n忽然间怒放开来。\n两天后，绸缎般淡粉色的花瓣\n围着树干堆积着\n就像脱下来的衬裙。\n还记得从前的春天有多长吗？\n还记得从第一次牵住手指。\n到第一次真正的吻曾经需要多久吗？而这之后。\n还记得另一次漫长的等待，无尽的摩挲。\n就为了解开一粒纽扣吗？\n作者 / [美国]丽泽·穆勒1\nMAGNOLIA This year spring and summer decided\nto make it quick, roll themselves into one\nseason of three days\nand steam right out of winter.\nIn the front yard the reluctant\nmagnolia buds lost control\nand suddenly stood wide open.\nTwo days later their pale pink silks\nheaped up around the trunk","title":"读一首诗再睡觉｜MAGNOLIA"},{"content":"机器学习的三要素：模型、学习准则、优化。\n模型 线性模型：$f(x,\\theta)=\\textbf{w}^T\\textbf{x}+b$\n非线性模型：广义的非线性模型可以写为多个非线性基函数𝜙(𝒙) 的线性组合。$f(x,\\theta)=\\textbf{w}^T\\phi(\\textbf{x})+b$ 如果 $\\phi(\\textbf{x})$本身为可学习的基函数，则$f(x,\\theta)$就等价于神经网络模型\n学习准则 模型的好坏可以通过期望风险衡量\n常见的损失函数：\n0-1损失：不连续且导数为 0，难以优化 平方损失：一般不适用于分类问题。$y$为实数值 $$\\mathcal{L}(y, f(\\mathbf{x};\\theta))=\\frac{1}{2}\\left(y-f(\\mathbf{x};\\theta))\\right)^2$$ 交叉熵：一般用于分类问题 $\\mathbf{y}$为one-hot标签向量 $$ \\begin{align} \\mathcal{L}(\\mathbf{y}, f(\\mathbf{x};\\theta))\u0026amp;=-\\mathbf{y}\\mathrm{log}f(\\mathbf{x};\\theta) \\\\ \u0026amp;= - \\sum^{C}_{c=1}y_c\\mathrm{log}f_c(\\mathbf{x};\\theta) \\\\ \u0026amp;= -\\mathrm{log}f_y(\\mathbf{x};\\theta) \\end{align} $$ 因此，交叉熵损失函数也就是负对数似然函数。 经验风险最小化(Empirical Risk Minimization，ERM)原则：找到一组参数使得经验风险最小。 过拟合\n在训练集上错误率很低，但是在未知数据上错误率很高.往往是由于训练数据少和噪声以及模型能力强等原因造成的\n为了解决过拟合问题， 一般在经验风险最小化的基础上再引入参数的正则化 (Regularization)来限制模型能力，使其不要过度地最小化经验风险。这种准则就是结构风险最小化(Structure Risk Minimization，SRM)准则 $$ \\theta^*=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^N \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right)+\\lambda \\mathscr{l}_p(\\theta) $$\n$\\mathscr{l}_2$范数正则化项，各个参数的平方和的开方值，用来减少参数空间，避免过拟合; $\\lambda$用来控制正则化的强度。\n$\\mathscr{l}_1$范数正则化项，各个参数的绝对值之和，通常会使得参数有一定稀疏性。\n加入正则化后，参数被限制到了一定的区域，等价于下面带约束条件的优化问题， $$ \\begin{aligned} \u0026amp; \\theta^*=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^N \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right), \\\\ \u0026amp; \\text { s.t. } \\quad \\ell_p(\\theta) \\leq d \\end{aligned} $$ $\\mathcal{F}$为函数$f(\\theta)$的等高线(为简单起见，这里用直线表示)。可以看出，$\\mathscr{l}_1$范数的约束通常会使得最优解位于坐标轴上，意味着某一维会变为0，从而使得最终的参数为稀疏性向量。 $\\mathscr{l}_2$参数取值空间是圆形，比较平滑，很难与损失函数的曲线相交在顶点上，但是它会使得参数更接近与0。\n不同范数约束条件下的最优化问题示例\n$\\mathscr{l}_2$范数约束条件下的最优化问题示例\n$\\mathscr{l}_1$范数约束条件下的最优化问题示例\n从贝叶斯学习的角度来讲，正则化是引入了参数的先验分布，使其不完全依赖训练数据1。\n优化 参数是模型的参数 超参数是定义模型结构或优化策略的参数，e.g. learning rate\n针对梯度下降的优化算法，除了加正则化项之外，还可以通过提前停止来防止过拟合。如果在验证集上的错误率不再下降，就停止迭代。\n梯度下降 批量梯度下降法(Batch Gradient Descent，BGD)在每次迭代时需要计算每个样本上损失函数的梯度并求和。 在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法(Stochastic Gradient Descent，SGD)\n随机梯度下降实现简单，收敛速度也非常快，因此使用非常广泛。随机梯度下降相当于在批量梯度 下降的梯度上引入了随机噪声，在非凸优化问题中，随机梯度下降更容易逃离局部最优点。\n小批量梯度下降法(Mini-Batch Gradient Descent)是批量梯度下降和随机梯度下 降的折中.每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率\n批量大小的影响\n批量大小不影响随机梯度的期望，但是会影响随机梯度的方差。\n批量越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定，因此可以设置较大的学习率。\n而批量较小时，需要设置较小的学习率，否则模型会不收敛。\n小批量梯度下降中，每次选取样本数量对损失下降的影响\n从(a)可以看出，每次迭代选取的批量样本数越多，下降效果越明显，并且曲线越平滑。当每次选取一个样本时（相当于随机梯度下降），损失整体是下降趋势，但局部看会来回震荡。 从(b)可以看出，如果按整个数据集迭代的来看损失变化情况，则小批量样本数越小，下降效果越明显。 学习率 学习率衰减 梯级衰减，线性衰减 逆时衰减：$\\alpha_t=\\alpha_0\\frac{1}{1+\\beta\\times t}$ 指数衰减：$\\alpha_t=\\alpha_0\\beta^t$ 自然指数衰减：$\\alpha_t=\\alpha_0\\ \\mathrm{exp}(-\\beta\\times t)$ 其中初始化学习率为$\\alpha_0$，迭代轮次$t$，$\\beta$为衰减率，一般为0.96 周期性学习率调整 TODO\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://goen-kkk.github.io/posts/dl/dl-0/","summary":"机器学习的三要素：模型、学习准则、优化。\n模型 线性模型：$f(x,\\theta)=\\textbf{w}^T\\textbf{x}+b$\n非线性模型：广义的非线性模型可以写为多个非线性基函数𝜙(𝒙) 的线性组合。$f(x,\\theta)=\\textbf{w}^T\\phi(\\textbf{x})+b$ 如果 $\\phi(\\textbf{x})$本身为可学习的基函数，则$f(x,\\theta)$就等价于神经网络模型\n学习准则 模型的好坏可以通过期望风险衡量\n常见的损失函数：\n0-1损失：不连续且导数为 0，难以优化 平方损失：一般不适用于分类问题。$y$为实数值 $$\\mathcal{L}(y, f(\\mathbf{x};\\theta))=\\frac{1}{2}\\left(y-f(\\mathbf{x};\\theta))\\right)^2$$ 交叉熵：一般用于分类问题 $\\mathbf{y}$为one-hot标签向量 $$ \\begin{align} \\mathcal{L}(\\mathbf{y}, f(\\mathbf{x};\\theta))\u0026amp;=-\\mathbf{y}\\mathrm{log}f(\\mathbf{x};\\theta) \\\\ \u0026amp;= - \\sum^{C}_{c=1}y_c\\mathrm{log}f_c(\\mathbf{x};\\theta) \\\\ \u0026amp;= -\\mathrm{log}f_y(\\mathbf{x};\\theta) \\end{align} $$ 因此，交叉熵损失函数也就是负对数似然函数。 经验风险最小化(Empirical Risk Minimization，ERM)原则：找到一组参数使得经验风险最小。 过拟合\n在训练集上错误率很低，但是在未知数据上错误率很高.往往是由于训练数据少和噪声以及模型能力强等原因造成的\n为了解决过拟合问题， 一般在经验风险最小化的基础上再引入参数的正则化 (Regularization)来限制模型能力，使其不要过度地最小化经验风险。这种准则就是结构风险最小化(Structure Risk Minimization，SRM)准则 $$ \\theta^*=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^N \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right)+\\lambda \\mathscr{l}_p(\\theta) $$\n$\\mathscr{l}_2$范数正则化项，各个参数的平方和的开方值，用来减少参数空间，避免过拟合; $\\lambda$用来控制正则化的强度。\n$\\mathscr{l}_1$范数正则化项，各个参数的绝对值之和，通常会使得参数有一定稀疏性。\n加入正则化后，参数被限制到了一定的区域，等价于下面带约束条件的优化问题， $$ \\begin{aligned} \u0026amp; \\theta^*=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^N \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right), \\\\ \u0026amp; \\text { s.","title":"DL复习｜机器学习概论"},{"content":" scaled dot product attention. source: Stefania Cristina\n$$Attention(Q,K,V)=softmax\\left(\\frac{QK^{T}}{\\sqrt{d_k}}\\right)V$$\n写一个self_attention function 假如input的dim是batch_size, seq_len, hidden_dim，写一个self attention function。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import torch import math import torch.nn.functional as F import pytorch_lightning as pl \u0026#39;\u0026#39;\u0026#39; q,k,v = (batch_size, seq_len, dim) \u0026#39;\u0026#39;\u0026#39; def self_attention(q, k, v, mask=None): d_k = k.size()[-1] attn_logits = torch.matmul(q, k.transpose(-2,-1)) attn_logits = attn_logits / math.sqrt(d_k) if mask is not None: att_logits = attn_logits.masked_fill(mask == 0, -9e15) scores = F.softmax(attn_logits, dim=-1) # 计算自注意力权重 values = torch.matmul(scores, v) # 计算自注意力分数 return values, scores ChatGPT版\n这里实现的self attention函数接受一个维度为(batch_size, seq_length, input_dim)的张量作为输入，其中batch_size表示批次大小，seq_length表示序列长度，input_dim表示输入特征的维度。在函数内部，我们首先使用三个线性层将输入特征映射到query、key和value空间。然后，我们通过计算query和key的点积，除以一个可学习的缩放因子，再进行softmax操作，得到注意力权重。最后，我们将注意力权重与value张量相乘，得到注意力输出，再将其映射回原始维度，并添加残差连接和层归一化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import torch import torch.nn.functional as F class SelfAttention(torch.nn.Module): def __init__(self, input_dim, hidden_dim=None): super(SelfAttention, self).__init__() self.input_dim = input_dim self.hidden_dim = hidden_dim if hidden_dim else input_dim // 2 self.query = torch.nn.Linear(self.input_dim, self.hidden_dim) self.key = torch.nn.Linear(self.input_dim, self.hidden_dim) self.value = torch.nn.Linear(self.input_dim, self.hidden_dim) self.output = torch.nn.Linear(self.hidden_dim, self.input_dim) def forward(self, x): Q = self.query(x) K = self.key(x) V = self.value(x) # 计算注意力权重 attn_weights = F.softmax(torch.bmm(Q, K.transpose(1, 2)) / torch.sqrt(torch.tensor(self.hidden_dim)), dim=2) # 计算注意力输出 attn_outputs = torch.bmm(attn_weights, V) # 将注意力输出映射回原始维度 attn_outputs = self.output(attn_outputs) # 添加残差连接和层归一化 attn_outputs = F.layer_norm(attn_outputs + x, [attn_outputs.size(-1)]) return attn_outputs ","permalink":"https://goen-kkk.github.io/posts/interv/transformer/","summary":"scaled dot product attention. source: Stefania Cristina\n$$Attention(Q,K,V)=softmax\\left(\\frac{QK^{T}}{\\sqrt{d_k}}\\right)V$$\n写一个self_attention function 假如input的dim是batch_size, seq_len, hidden_dim，写一个self attention function。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import torch import math import torch.nn.functional as F import pytorch_lightning as pl \u0026#39;\u0026#39;\u0026#39; q,k,v = (batch_size, seq_len, dim) \u0026#39;\u0026#39;\u0026#39; def self_attention(q, k, v, mask=None): d_k = k.size()[-1] attn_logits = torch.matmul(q, k.transpose(-2,-1)) attn_logits = attn_logits / math.sqrt(d_k) if mask is not None: att_logits = attn_logits.","title":"Interview｜Transformer"},{"content":"","permalink":"https://goen-kkk.github.io/posts/pieces/","summary":"","title":"Collection｜Pieces"},{"content":"resources Free Magazines Online：外文期刊\nDynamic Wallpaper Club：墙纸\nneetcode：刷题网站\nTOFUGU：日语文章博客\nOpen Library：图书\nlabml.ai：神经网络和相关算法的简单PyTorch实现的集合\ntools carbon：导出美观的代码\nEmoji Cheat Sheet：Emoji\nslide slidesgo\nJust Free Slide\nHiSlide\nHappy Hues\nChatGPT Poe\nforefront.ai\nArtist Harrys\nWebsite Codewars\n","permalink":"https://goen-kkk.github.io/posts/collection/","summary":"resources Free Magazines Online：外文期刊\nDynamic Wallpaper Club：墙纸\nneetcode：刷题网站\nTOFUGU：日语文章博客\nOpen Library：图书\nlabml.ai：神经网络和相关算法的简单PyTorch实现的集合\ntools carbon：导出美观的代码\nEmoji Cheat Sheet：Emoji\nslide slidesgo\nJust Free Slide\nHiSlide\nHappy Hues\nChatGPT Poe\nforefront.ai\nArtist Harrys\nWebsite Codewars","title":"Collection｜Fancy websites"}]